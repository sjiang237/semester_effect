---
title: "Models_Testing"
author: "Shuheng Jiang"
date: "2024-10-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
### Handle conflicts
```{r}
#| message: false
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
# We also will need to resolve a new conflict using the following code
# Alternatively, John demonstrates code you can use when you load this library to prevent conflicts
conflictRules("Matrix", mask.ok = c("expand", "pack", "unpack"))
```

### Load required packages 
```{r}
#| message: false
#| warning: false
library(kableExtra, exclude = "group_rows") # for displaying formatted tables w/ kbl()
library(janitor, include.only = c("clean_names", "tabyl"))
library(cowplot, include.only = "plot_grid")
library(tidyverse) # for general data wrangling
library(tidymodels) # for modeling
library(kknn)
library(discrim, exclude = "smoothness")
library(xfun, include.only = "cache_rds")
library(cowplot, include.only = "plot_grid")
library(readxl)
library(dplyr)
library(lubridate)
library(skimr)
library(tidyselect)
library(tibble)
library(effectsize)
library(lme4)
library(ggplot2)
library(effects)
library(nnet)
library(broom)
# Load the required packages
library(ggeffects)
```


### Source function scripts
```{r}
#| message: false
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
source("C:/Users/16089/OneDrive/Desktop/lab psych610/610710_functions.R")
```

### Specify other global settings
```{r}
#| include: false
theme_set(theme_classic())
options(tibble.width = Inf, dplyr.print_max=Inf)
```

### file path
```{r}
file_path <- "C:/Users/16089/OneDrive/Desktop/Greens lab/semester/raw_data"
```

```{r}
d_try <- read_csv(here::here(file_path, "Generic_Post_Survey_Combined.csv"), 
                   col_types = cols())
```


### Mediation
Let's verbally describe our hypothesized mediation model.
>> Higher Growth Mindset scores leads to higher self-control (lower grit score), which in turn leads to students choose to take the survey earlier in the semester.

# X = ADHD_clinical
# M = conscientious
# Y = days_since_start_of_the_semester

#### Other Mediation effect to explore: X: ucmrt, M:grit, Y: days
#### X: ucmrt, M = conscience, Y= days

# 1. There is a relationship between X and Y. Path c is significant.
```{r}
m1 <- lm(days_since_semester_start ~ adhd_clinical, data = d_try)
summary(m1)
```


```{r}
m2 <- lm(conscientiousness_score ~ adhd_clinical, data = d_try)
summary(m2)
```


```{r}
m3 <- lm(days_since_semester_start ~ conscientiousness_score + adhd_clinical, data = d_try)
summary(m3)
```
Yes! There is a mediation effect to explore; But the hypothesis might not be valid, since adhd is a clinical diagnosis and conscientiousness_score is a personality test score. 


```{r}
range(d_try$days_since_semester_start)
```


## Cluster Variable days_since_semester_start
```{r}
d_try$semester_phase <- cut(
  d_try$days_since_semester_start,
  breaks = c(-Inf, 39, 74, Inf),  # Define breakpoints based on days
  labels = c("start", "middle", "end"),
  include.lowest = TRUE
)
```
Linear SVM; show whether the group differ by mixed components, then 

```{r}
d_try <- d_try %>% select(participant_id, semester_phase, everything())
```


```{r}
ggplot(d_try, aes(x = semester_phase)) +
  geom_bar(fill = "lightblue") +
  labs(title = "Distribution of Semester Phases", 
       x = "Semester Phase", 
       y = "Frequency") +
  facet_wrap(~semester_id) +
  theme_minimal()
```


```{r}
ggplot(d_try, aes(x = semester_phase)) +
  geom_bar(fill = c("lightblue", "lightgreen", "lightcoral")) +
  labs(title = "Distribution of Semester Phases", 
       x = "Semester Phase", 
       y = "Frequency") + 
  theme_minimal() 
```


```{r}
d_try$has_na <- rowSums(is.na(d_try)) > 0
ggplot(d_try, aes(x = semester_phase, fill = has_na)) +
  geom_bar() +
  scale_fill_manual(values = c("lightblue", "lightcoral"), labels = c("No NAs", "Has NAs")) +
  scale_x_discrete(labels = c("Spring-2018" = "Sp18", "Fall-2018" = "Fa18", 
                              "Spring-2019" = "Sp19", "Fall-2019" = "Fa19",
                              "Spring-2020" = "Sp20", "Fall-2020" = "Fa20",
                              "Spring-2021" = "Sp21", "Fall-2021" = "Fa21",
                              "Spring-2022" = "Sp22", "Fall-2022" = "Fa22",
                              "Spring-2023" = "Sp23", "Fall-2023" = "Fa23")) +
  labs(title = "Distribution of Missing Values by Semester",
       x = "Semester Phase",
       y = "Count",
       fill = "Missing Values") +
  facet_wrap(~semester_id)
  theme_minimal()

```




## Running Explanantory Models 
Linear Mixed-Effects Model (LMM)
```{r}
m1 <- lmer(matrices_hit_rate ~ semester_phase + (1|semester_id) + adhd_clinical + grit_overall + conscientiousness_score + neuroticism_score + extraversion_score + openness_score + agreeableness_score + growth_mindset_score, data = d_try)
```

run a new model: 
matrices_hit_rate ~ semester_phase + (1|semester_id) + adhd_clinical + grit_overall + conscientiousness_score

```{r}
summary(m1)
```

Scaled Residuals show the difference between observed and predicted values. Here, the residuals are symmetrically distributed around zero, indicating a reasonable fit.

Intercept: 0.6887528 is the estimated baseline hit rate for the reference level of semester_phase ("start") and when all other variables are at their average values. This suggests that, on average, students have a hit rate of ~0.69 at the start of the semester.

semester_phasemiddle: The coefficient is -0.0401502, with a t-value of -2.305. This indicates that, on average, students in the middle of the semester have a lower matrices hit rate by 0.040 units compared to the start of the semester, holding other variables constant. This is a significant effect at the p < .05 level (although p values are not provided directly in the output).

semester_phaseend: The coefficient is -0.0524175, with a t-value of -3.002. This suggests that students at the end of the semester have a lower hit rate by 0.052 units compared to the start of the semester, holding other variables constant. This effect is significant as well.

neuroticism_score: The coefficient is -0.0342699 with a t-value of -3.766, indicating a significant negative relationship between neuroticism and matrices hit rate. A one-unit increase in neuroticism is associated with a 0.034 decrease in hit rate.

extraversion_score: The coefficient is -0.0491756 with a t-value of -5.389, indicating a significant negative relationship between extraversion and matrices hit rate. A one-unit increase in extraversion is associated with a 0.049 decrease in hit rate.

conscientiousness_score: The coefficient is -0.0382802 with a t-value of -2.825, suggesting a significant negative relationship between conscientiousness and matrices hit rate. A one-unit increase in conscientiousness is associated with a 0.038 decrease in hit rate.

openness_score: The coefficient is 0.0668201 with a t-value of 6.394, indicating a significant positive relationship between openness and matrices hit rate. A one-unit increase in openness is associated with a 0.067 increase in hit rate.



```{r}
car::Anova(m1, type = 3, test = "F")
```

Significant Predictors: semester_phase, neuroticism_score, extraversion_score, conscientiousness_score, and openness_score.

The significant effect of semester_phase suggests that when in the semester the survey is taken impacts matrices hit rate.
Personality traits such as neuroticism, extraversion, conscientiousness, and openness have strong and significant effects on performance, indicating that these traits are important predictors of cognitive performance.

The significant effect of semester_phase suggests that when students take the survey during the semester (start, middle, or end) influences their performance. This finding could be valuable for optimizing the timing of data collection in future studies. Additionally, the influence of personality traits highlights the importance of considering individual differences when assessing cognitive performance.



## Post-Hoc Test
```{r}

```



```{r}
predicted_effects <- ggpredict(m1, terms = c("semester_phase"))

# Plot the predicted effects
plot(predicted_effects) +
  ggtitle("Predicted Effects of Semester Phase on Matrices Hit Rate") +
  xlab("Semester Phase") +
  ylab("Predicted Matrices Hit Rate") +
  theme_minimal()
# ggsignif 
# show violin plot 
# plot dot and jitter 
```


```{r}
# Visualize interaction effects between semester_phase and other variables
predicted_effects <- ggpredict(m1, terms = c("semester_phase", "adhd_clinical"))

# Plot the interaction effects
plot(predicted_effects) +
  ggtitle("Interaction Effects of Semester Phase and ADHD Clinical Scores") +
  xlab("Semester Phase") +
  ylab("Predicted Matrices Hit Rate") +
  theme_minimal()

```

```{r}
sjPlot::plot_model(m1, type = "re", show.values = TRUE, value.offset = 0.3) +
  ggtitle("Random Effects of Semester ID on Intercept") +
  theme_minimal()
```
This could mean that the semester_id variable does not have a significant impact on the intercept of the model, suggesting that the average matrices_hit_rate is fairly consistent across semesters.


```{r}
sjPlot::plot_model(m1, type = "est", show.values = TRUE, value.offset = 0.3) + ggtitle("Fixed Effects Coefficients for Matrices Hit Rate Model") +
  theme_minimal()
```


Considering not doing intercept of semester_id, instead, do the slope for semester_phase within semester_id? Run another model 

## Multinomial logistic 
```{r}
d_try$days_since_semester_start_category <- factor(d_try$semester_phase, levels = c("beginning", "middle", "end"))
```


```{r}
m2 <- multinom(semester_phase ~ matrices_hit_rate + adhd_clinical + grit_overall + neuroticism_score + extraversion_score + conscientiousness_score + openness_score + agreeableness_score + growth_mindset_score, data = d_try)
```

```{r}
summary(m2)
```

Interpret the model output: 
Summary of Key Findings
Significant Predictors: While the p-values are not provided in the summary, coefficients with larger absolute values and smaller standard errors are likely to be significant. To confirm significance, use a z-test or likelihood ratio test.

Negative Impact on "middle" and "end": matrices_hit_rate and conscientiousness_score both have negative coefficients, suggesting that higher scores on these variables decrease the likelihood of completing the survey in the "middle" or "end" of the semester.
Positive Impact on "middle" and "end": extraversion_score and openness_score have positive coefficients, suggesting that higher scores increase the likelihood of being in the "middle" or "end" phases relative to the "start."
Non-significant Predictors: adhd_clinical, grit_overall, agreeableness_score, and growth_mindset_score likely have non-significant effects given their small coefficients and relatively large standard errors.




```{r}
exp(coef(m2))
```


Summary of Key Findings
Impact of Cognitive Scores:

Higher matrices_hit_rate is strongly associated with completing the survey earlier in the semester ("start"), as evidenced by the significantly lower odds for both the "middle" and "end" phases.
Impact of Personality Traits:

Extraversion and openness are associated with higher odds of completing the survey later in the semester ("middle" or "end").
Conscientiousness has the opposite effect, with higher scores being associated with completing the survey earlier in the semester.
Non-Significant Predictors:

Variables like adhd_clinical, agreeableness, and growth_mindset_score do not have a substantial impact on the timing of survey completion.


```{r}
# Get the coefficient names from the model
variable_names <- rownames(summary(m2)$coefficients)

# Create a new variable that combines predictor names with categories (e.g., "matrices_hit_rate_middle")
variable_names_combined <- as.vector(outer(colnames(summary(m2)$coefficients), 
                                           rownames(summary(m2)$coefficients), 
                                           FUN = paste, sep = "_"))

z_values <- summary(m2)$coefficients / summary(m2)$standard.errors

# Calculate p-values based on z-values
p_values <- 2 * (1 - pnorm(abs(z_values)))

# Create the significance table with variable names included
significance_table <- data.frame(
  Variable = rep(variable_names_combined, each = 1),  # Replicate variable names
  Estimate = as.vector(summary(m2)$coefficients),
  Std_Error = as.vector(summary(m2)$standard.errors),
  z_value = as.vector(z_values),
  p_value = as.vector(p_values)
)

# Print the significance table with variable names
significance_table

# Display the table with variable names using knitr::kable
library(knitr)
kable(significance_table, digits = 4, caption = "Significance Test Results for Multinomial Logistic Regression Model")

```



```{r}
coefficients <- summary(m2)$coefficients
standard_errors <- summary(m2)$standard.errors

# Calculate odds ratios, lower and upper confidence intervals
odds_ratios <- exp(coefficients)
lower_ci <- exp(coefficients - 1.96 * standard_errors)
upper_ci <- exp(coefficients + 1.96 * standard_errors)

# Convert the data into a tidy format for plotting
odds_data <- data.frame(
  Variable = rep(rownames(coefficients), times = ncol(coefficients)),
  Category = rep(colnames(coefficients), each = nrow(coefficients)),
  Odds_Ratio = as.vector(odds_ratios),
  Lower_CI = as.vector(lower_ci),
  Upper_CI = as.vector(upper_ci)
)

# Create the odds ratio plot using ggplot2
ggplot(odds_data, aes(x = Variable, y = Odds_Ratio, color = Category)) +
  geom_pointrange(aes(ymin = Lower_CI, ymax = Upper_CI), position = position_dodge(width = 0.5)) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +  # Add reference line at OR = 1
  coord_flip() +  # Flip the axes for easier reading
  labs(title = "Odds Ratios with 95% Confidence Intervals for Semester Phases",
       x = "Predictor Variables",
       y = "Odds Ratio (Log Scale)") +
  scale_y_log10() +  # Use log scale for odds ratios
  theme_minimal()
```


Linkage clustering...

What is the best way to cluster? SVM clustering


## Running AIC models comparison 

